{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "joint-jacket",
   "metadata": {},
   "source": [
    "# Predicting House Prices with Linear Regression\n",
    "\n",
    "\n",
    "This notebook will show how to train and evaluate a linear regression model to predict house prices using the *size* (in a square foot) and the *number of bedrooms* as features.\n",
    "\n",
    "We start by importing the required functions and classes. Here we import the following:\n",
    "\n",
    "* The `pyplot` module from the `matplotlib` library for creating the visulizations needed.\n",
    "* We import the `pandas` library for loading the data from a CSV file.\n",
    "* From the `sklearn.model_selection`, we import the `train_test_split()` function which we use to split our data into training and testing data.\n",
    "* From the `sklearn.linear_model`, we import the `LinearRegression` class to create the object that we use to first our model.\n",
    "* From the `sklearn.metrics`, we import the `mean_squared_error()`, `r2_score()` function to evaluate the regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                          # the visualizations  framework\n",
    "import pandas as pd                                      # data processing, CSV file I/O\n",
    "from sklearn.model_selection import train_test_split     # split the data in train/test\n",
    "from sklearn.linear_model import LinearRegression        # the linear regression model\n",
    "from sklearn.metrics import mean_squared_error, r2_score # evaluation metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-premiere",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The data set we use here is stored in the CSV file under `\"./data/house_prices.csv\"`. We use the `pandas` library short name (i.e., `pd`) to call the `read_csv` method, which takes the file path as an argument. The method returns a data frame that is assigned to the variable `data`. We use that variable to show the top five rows (using the `head` method) and then print the summary statistics (count, mean, standard deviation, etc.) using the `describe` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "\n",
    "data = pd.read_csv(\"./data/house_prices.csv\")\n",
    "\n",
    "print(\"First five rows:\")\n",
    "print(data.head())  # dsiplay the first 5 rows\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Summary statsitics:\")\n",
    "print(data.describe())  # show the the summary statistics for the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-stranger",
   "metadata": {},
   "source": [
    "As you can see, the dataset has three columns:\n",
    "\n",
    "* **Size**: the size of the house in square feet.\n",
    "* **Bedrooms**: the number of bedrooms in the house\n",
    "* **Price**: the price of the house in USD (our *target label*).\n",
    "\n",
    "The number of examples in the data set (as shown in the summary statistics) is 47. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-yemen",
   "metadata": {},
   "source": [
    "# Spliting the Data into Train/Test\n",
    "\n",
    "Before splitting the data, we get two slices from the data frame (i.e., `data`). The first slice contains the features (i.e., `size` and `bedrooms`), which we assign to a variable named `X`. The second slice contains the target (i.e., `price`), which we set to the `y` variable. \n",
    "\n",
    "We then use the `train_test_split()` to split our data into training and testing data randomly. The function expects two sequences of data: \n",
    "\n",
    "* `X` sequence containing the features.\n",
    "* `y` sequence containing the target label.\n",
    "\n",
    "In addition to the sequence, we pass two parameters: \n",
    "\n",
    "* `test_size` is the number that defines the size of the test set.\n",
    "* `random_state`, which is an integer that specifies that state of the random split.  **To make your tests reproducible, it is essential to set this parameter. Otherwise, you will get different splits each time you run your code.**\n",
    "\n",
    "`train_test_split()` performs the split and returns four sequences in this order:\n",
    "\n",
    "1. `X_train`: The training part of the first sequence (`X`)\n",
    "2. `X_test`: The test part of the first sequence (`X`)\n",
    "3. `y_train`: The training part of the second sequence (`y`)\n",
    "4. `y_test`: The test part of the second sequence (`y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]   # features is all the columns except last one\n",
    "y = data.iloc[:, -1]    # the target label\n",
    "\n",
    "# split the data into training (70%) and testing (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-insulin",
   "metadata": {},
   "source": [
    "## Visualizing the Data \n",
    "\n",
    "Before you fit the model, it is good to explore the relationships between the different variables within your data. You can gain more insights into the dependent variables that might serve as good predictors of the target label. You can either keep the variables,  remove them, or combine them with others based on such insights. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us visulize the data\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))   # create plot gird with 1 row and 2 columns\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.scatter(X_train.iloc[:, i], y_train, s=30) # plot the feature against the label (i.e., price)\n",
    "    ax.set_xlabel(data.columns[i])        \n",
    "    ax.set_ylabel(data.columns[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-somerset",
   "metadata": {},
   "source": [
    "Here we make two scatter plots for each of the feature variables against the label. As you can see, there is a positive correlation between $Size-Price$ and $Bedrooms-Price$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-wheel",
   "metadata": {},
   "source": [
    "## Creating the Model\n",
    "Now that data is split, it is time to fit the model. With scikit-learn, we do this in two lines of code. The first line creates a regressor object (i.e., `reg`) using the `LinearRegression()` class we imported earlier. The second line calls the `reg` object's `fit()` method by passing two parameters: `X_train` and `y_train`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create  the model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-denver",
   "metadata": {},
   "source": [
    "## The Model Parmeters\n",
    "After fitting the model, it is time to inspect what our model has learned.  Here we are interested in knowing about the model parameter. Recall that  a linear regression model  has the following form:\n",
    "$y = w_0 + w_1x_1 + w_2x_2 + \\dots + w_nx_n$\n",
    "\n",
    "After learning, the vector $w = [w_0, w_1, \\dots, w_n]$ will hold the model parameters. Using scikit-learn terminology,  the values $w_1, \\dots, w_n$ are called the **coefficients**, and $w_0$ is called the **intercept**. \n",
    "\n",
    "The code below shows The code below shows how to get the values of coefficients and intercept of the learned regressor.  The output should look like the following:\n",
    "\n",
    "```\n",
    "coefficient:  [  131.77059948 -4570.48794717]\n",
    "intercept/bias: 89793.79977782266\n",
    "```\n",
    "\n",
    "Given this, our model function can be written as:\n",
    "\n",
    "$price = 89793.8 +  131.8 \\times size - 4570.5 \\times bedrooms $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let use print the model paramters\n",
    "print(\"coefficient: \", reg.coef_)\n",
    "print(\"intercept/bias:\", reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa8cd5",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "Making predictions using our model is as easy as fitting the model in the first place. For example, let us say we want to predict the price of the house whose size is 400 square feet and has four bedrooms. To do so, pass the array data frame that contains a single row and then we pass this data frame  to the `predict()` method of our regression object `reg`, which will calculate the corresponding y value based on the learned model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us predict the value of the house with\n",
    "# 400 sqaure feet\n",
    "# 4 bedrooms\n",
    "\n",
    "# sample data disctonary\n",
    "sample_data = {\"Size\": [400],\n",
    "              \"Bedrooms\": [4]}\n",
    "\n",
    "# create a data frame for our sample data\n",
    "sample_df = pd.DataFrame(sample_data, columns=[\"Size\", \"Bedrooms\"])\n",
    "\n",
    "value = reg.predict(sample_df)\n",
    "\n",
    "print(\"The predicted price for a 400sqt house with 4 bedrooms is: \", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b8ff5d",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Last, we evaluate our model using various regression metrics by comparing our model's predictions against the ground truth.  We first call the `predict()` method by passing the `X_test` split of the data. The returned predictions for each of the examples in the `X_test` array is saved in `y_pred` array. We then pass the `y_pred` array along with the ground truth  (i.e., `y_test`) to the scoring functions  `mean_squared_error()` and  `r2_score()` to calculate mean squared error (MSE), root mean squared error (RMSE), and the coefficient of determination $R^2$.  These metrics provide some hint of the performance of the `LinearRegression()` model on the given data set.\n",
    "\n",
    "Note, these metrics are of little value if the performance of the used model is not compared with the performance of other models.  Therefore, I encourage you to use the train another model (perhaps `sklearn.svm.LinearSVR`) and compare it  against the linear regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we evaluate the model\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# calculate the MSE, RMSE and R^2\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"MSE = {mse:.2f}\")\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)     \n",
    "print(f\"RMSE = {rmse:.2f}\")\n",
    "\n",
    "r2score = r2_score(y_test, y_pred)\n",
    "print(f\"R2 Score = {r2score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0984c706",
   "metadata": {},
   "source": [
    "\n",
    "**Congratulations!**\n",
    "\n",
    "You have just built your first machine learning flow using the scikit-learn library. Don't just stop here. Play around with the provided code and try to build other regression models. See if you can find a model that gives a better performance than the one obtained here. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf9a9eee405a0088de7ccf5832a78f5819a8f68f034f45858f658735d571460f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('Intro2AI': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
